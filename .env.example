# OsMEN Environment Configuration
# Copy this file to .env and customize for your environment
#
# ⚠️  CRITICAL SECURITY WARNING ⚠️
# DO NOT use these example values in production!
# ALL passwords, secrets, and API keys MUST be changed before deployment!
# Using example values in production is a SEVERE SECURITY RISK!

# ============================================================================
# CORE APPLICATION SETTINGS
# ============================================================================

# Environment: development, staging, production
ENVIRONMENT=development

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# CORS origins (comma-separated for multiple)
ALLOWED_ORIGINS=http://localhost:3000

# API rate limiting (requests per minute)
RATE_LIMIT_PER_MINUTE=120

# Force HTTPS redirect (set to 'true' in production)
ENFORCE_HTTPS=false

# ============================================================================
# SECURITY SETTINGS - CHANGE THESE IN PRODUCTION!
# ============================================================================

# Session secret key - MUST be changed for production!
# Generate with: python3 -c "import secrets; print(secrets.token_hex(32))"
SESSION_SECRET_KEY=dev-session-secret-change-me

# Web dashboard secret key - MUST be changed for production!  
# Generate with: python3 -c "import secrets; print(secrets.token_hex(32))"
WEB_SECRET_KEY=dev-secret-key-change-in-production

# Web dashboard admin credentials
WEB_ADMIN_USERNAME=admin
# Password hash for admin user (use bcrypt)
# Generate with: python3 scripts/security/hash_password.py
# Default password is 'admin' - CHANGE THIS!
WEB_ADMIN_PASSWORD_HASH=$$2b$$12$$KIXxLV3qZ.gY8yH7n7P7Q.xQZ7vXZX8F1Y2Y3Z4Z5Z6Z7Z8Z9Z0Z1

WEB_ADMIN_ROLE=admin
WEB_DEFAULT_ROLE=viewer

# Session cookie security (set to 'true' in production)
SESSION_COOKIE_SECURE=false
SESSION_COOKIE_MAX_AGE=3600

# Login rate limiting
WEB_LOGIN_MAX_ATTEMPTS=5
WEB_LOGIN_WINDOW_SECONDS=60

# ============================================================================
# OAUTH TOKEN ENCRYPTION (Team 5 - Token Security)
# ============================================================================

# OAuth Encryption Key for secure token storage
# Generate with: python3 scripts/automation/generate_encryption_key.py
# or: python3 -c 'from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())'
OAUTH_ENCRYPTION_KEY=

# ============================================================================
# ERROR TRACKING (Optional)
# ============================================================================

# Sentry DSN for error tracking (leave empty to disable)
SENTRY_DSN=
SENTRY_ENVIRONMENT=development

# ============================================================================
# DATABASE CONFIGURATION
# ============================================================================

# OsMEN Application Database (separate from n8n/Langflow)
OSMEN_DB_HOST=localhost
OSMEN_DB_PORT=5432
OSMEN_DB_NAME=osmen_app
OSMEN_DB_USER=osmen_app
# ⚠️  SECURITY: Replace with a strong password!
OSMEN_DB_PASSWORD=your-secure-database-password-here
OSMEN_DB_POOL_MIN=1
OSMEN_DB_POOL_MAX=5

# ============================================================================
# N8N WORKFLOW AUTOMATION
# ============================================================================

N8N_BASIC_AUTH_USER=admin
# ⚠️  SECURITY: Change this password immediately!
# This is an EXAMPLE VALUE and must NOT be used in production!
N8N_BASIC_AUTH_PASSWORD=your-secure-password-here
N8N_HOST=localhost
N8N_PORT=5678

# ============================================================================
# POSTGRESQL (Shared by Langflow and n8n)
# ============================================================================

POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
# ⚠️  SECURITY: Replace with a strong password!
POSTGRES_PASSWORD=your-secure-postgres-password-here
POSTGRES_DB=postgres

# ============================================================================
# LLM PROVIDER CONFIGURATION
# Configure at least ONE provider for agents to work
# Priority: OpenAI > GitHub Copilot > Amazon Q > Claude > LM Studio > Ollama
# ============================================================================

# --- PRIMARY: Production Cloud LLM Agents ---

# OpenAI (GPT-4, Codex) - RECOMMENDED FOR GETTING STARTED
# Get API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4

# OpenAI OAuth (for web-based authentication)
# Note: OpenAI primarily uses API keys, OAuth is for wrapped flows
OPENAI_OAUTH_CLIENT_ID=your_openai_oauth_client_id_here
OPENAI_OAUTH_CLIENT_SECRET=your_openai_oauth_client_secret_here
OPENAI_OAUTH_REDIRECT_URI=http://localhost:8000/oauth/openai/callback

# GitHub Copilot
# Get token from: https://github.com/settings/tokens
GITHUB_TOKEN=your_github_token_here
COPILOT_API_URL=

# GitHub OAuth (for Copilot OAuth flow)
# Create OAuth App at: https://github.com/settings/developers
GITHUB_OAUTH_CLIENT_ID=your_github_oauth_client_id_here
GITHUB_OAUTH_CLIENT_SECRET=your_github_oauth_client_secret_here
GITHUB_OAUTH_REDIRECT_URI=http://localhost:8000/oauth/github/callback

# Amazon Q  
# Get credentials from: https://aws.amazon.com/q/
AWS_ACCESS_KEY_ID=your_aws_access_key_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_key_here
AWS_REGION=us-east-1

# Anthropic Claude
# Get API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-opus-20240229

# Google Gemini
# Get API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-pro

# --- SECONDARY: Local LLM Options (Privacy-Focused) ---

# LM Studio (Primary Local Option)
# Download from: https://lmstudio.ai
# Start LM Studio and load a model, then it will serve on port 1234
LM_STUDIO_URL=http://host.docker.internal:1234/v1
LM_STUDIO_MODEL=local-model

# Ollama (Secondary Local Option)
# Start with: docker-compose --profile ollama up -d
# Models will be downloaded automatically on first use
OLLAMA_URL=http://ollama:11434
OLLAMA_MODEL=llama2

# llama.cpp (Tertiary Local Option - Advanced Users)
LLAMACPP_PATH=~/llama.cpp
LLAMACPP_MODELS_PATH=~/llama-models

# ============================================================================
# VECTOR DATABASE & CACHING
# ============================================================================

# Qdrant Vector Database (for agent memory)
QDRANT_HOST=http://qdrant:6333
QDRANT_API_KEY=

# Langflow Configuration
LANGFLOW_HOST=http://langflow:7860

# Redis Cache Configuration
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_CACHE_DB=0
REDIS_CACHE_TTL_SECONDS=60

# ============================================================================
# AGENT CONFIGURATION
# ============================================================================

# Enable/disable individual agents

# Personal Productivity Team
PERSONAL_ASSISTANT_ENABLED=true
DAILY_BRIEF_ENABLED=true
FOCUS_GUARDRAILS_ENABLED=true

# Content Creation Team
CONTENT_CREATOR_ENABLED=true
AUDIOBOOK_CREATOR_ENABLED=true
PODCAST_CREATOR_ENABLED=true

# Communication Team
EMAIL_MANAGER_ENABLED=true
LIVE_CAPTION_ENABLED=true

# Knowledge Team
KNOWLEDGE_MANAGEMENT_ENABLED=true
SYLLABUS_PARSER_ENABLED=true
RESEARCH_INTEL_ENABLED=true

# System Team
OS_OPTIMIZER_ENABLED=true
BOOT_HARDENING_ENABLED=true

# Security Team
SECURITY_OPS_ENABLED=true

# Agent Team Coordination
AGENT_COORDINATOR_ENABLED=true
MULTI_AGENT_WORKFLOWS_ENABLED=true

# ============================================================================
# OAUTH TOKEN STORAGE
# ============================================================================

# Path to store OAuth tokens (GitHub, OpenAI, etc.)
OAUTH_TOKEN_PATH=./tokens

# ============================================================================
# TOOL INTEGRATIONS
# ============================================================================

# Codex CLI Configuration
# Uses OPENAI_API_KEY from above
CODEX_CLI_ENABLED=true
CODEX_MODEL=code-davinci-002

# Copilot CLI Configuration  
# Uses GITHUB_TOKEN from above
COPILOT_CLI_ENABLED=true

# Zoom Integration
ZOOM_API_KEY=your_zoom_api_key_here
ZOOM_API_SECRET=your_zoom_api_secret_here
ZOOM_WEBHOOK_SECRET=your_zoom_webhook_secret_here
ZOOM_LIVE_CAPTION_ENABLED=true

# Audiblez Configuration (Audiobook Creation)
AUDIBLEZ_API_KEY=your_audiblez_api_key_here
AUDIBLEZ_VOICE_MODEL=default
AUDIBLEZ_OUTPUT_FORMAT=mp3

# Vibevoice Configuration (Voice Cloning)
VIBEVOICE_API_KEY=your_vibevoice_api_key_here
VIBEVOICE_VOICE_SAMPLES_PATH=./voice_samples
VIBEVOICE_ENABLED=true

# Open Notebook Integration
OPENNOTEBOOK_PATH=./notebooks
OPENNOTEBOOK_SYNC_ENABLED=true

# Email Configuration (Gmail/Outlook)
EMAIL_PROVIDER=gmail
GMAIL_CLIENT_ID=your_gmail_client_id_here
GMAIL_CLIENT_SECRET=your_gmail_client_secret_here
GMAIL_REFRESH_TOKEN=your_gmail_refresh_token_here

OUTLOOK_CLIENT_ID=your_outlook_client_id_here
OUTLOOK_CLIENT_SECRET=your_outlook_client_secret_here
OUTLOOK_TENANT_ID=your_outlook_tenant_id_here

# Windows Tool Paths (leave default if not on Windows)
SYSINTERNALS_PATH=C:\\Tools\\Sysinternals
SIMPLEWALL_PATH=C:\\Program Files\\simplewall
FFMPEG_PATH=C:\\Tools\\ffmpeg\\bin

# Obsidian Vault Configuration
# Point this to your Obsidian vault directory
OBSIDIAN_VAULT_PATH=./obsidian-vault

# Notion Integration
NOTION_API_KEY=your_notion_api_key_here
NOTION_DATABASE_ID=your_notion_database_id_here
NOTION_SYNC_ENABLED=true

# Todoist Integration
TODOIST_API_KEY=your_todoist_api_key_here
TODOIST_SYNC_ENABLED=true

# ============================================================================
# MONITORING & LOGGING
# ============================================================================

# Logging configuration
LOG_LEVEL=INFO
LOG_FILE=./logs/osmen.log

# Prometheus metrics (set to 'true' to enable)
PROMETHEUS_METRICS_ENABLED=true

# ============================================================================
# LIBRARIAN RAG CONFIGURATION (osmen-librarian integration)
# ============================================================================

# Enable/disable Librarian integration
LIBRARIAN_ENABLED=true

# Librarian service URL (for Docker deployment)
LIBRARIAN_URL=http://librarian:8200

# Librarian data directory
LIBRARIAN_DATA_DIR=./data/librarian

# Librarian database path (ChromaDB)
LIBRARIAN_DB_PATH=./data/librarian/db

# Embedding model (requires GPU for best performance)
# Options: dunzhang/stella_en_1.5B_v5, all-MiniLM-L6-v2, text-embedding-ada-002
LIBRARIAN_EMBEDDING_MODEL=dunzhang/stella_en_1.5B_v5

# Default retrieval mode: foundation, lateral, factcheck
RAG_DEFAULT_MODE=lateral

# Number of results to return
RAG_TOP_K=5

# MMR diversity parameter for lateral mode (0.0-1.0)
RAG_MMR_LAMBDA=0.5

# Librarian API port
LIBRARIAN_API_PORT=8200

# Use librarian for knowledge management (integrates with KnowledgeAgent)
OSMEN_KNOWLEDGE_USE_LIBRARIAN=true

# ============================================================================
# MEDIA ENTERTAINMENT INTEGRATION
# ============================================================================

# TMDB (The Movie Database) - for movie/TV metadata
# Get API key from: https://www.themoviedb.org/settings/api
TMDB_API_KEY=your_tmdb_api_key_here

# OpenSubtitles - for subtitle search/download
# Get API key from: https://www.opensubtitles.com/en/consumers
OPENSUBTITLES_API_KEY=your_opensubtitles_api_key_here

# ============================================================================
# VOICE/AUDIO INTEGRATION
# ============================================================================

# ElevenLabs TTS (premium voice synthesis)
# Get API key from: https://elevenlabs.io/
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM

# Whisper Model Settings (for faster-whisper)
WHISPER_MODEL=base
WHISPER_DEVICE=cuda
WHISPER_COMPUTE_TYPE=float16

# ============================================================================
# CREATIVE TOOLS INTEGRATION
# ============================================================================

# InvokeAI (Stable Diffusion)
INVOKEAI_URL=http://localhost:9090

# ComfyUI
COMFYUI_URL=http://localhost:8188

# Meshy.ai (Text-to-3D API)
# Get API key from: https://www.meshy.ai/
MESHY_API_KEY=your_meshy_api_key_here

# ============================================================================
# GOOGLE/MICROSOFT CALENDAR & EMAIL
# ============================================================================

# Google Calendar/Gmail OAuth
# Create credentials at: https://console.cloud.google.com/
GOOGLE_CLIENT_ID=your_google_client_id_here
GOOGLE_CLIENT_SECRET=your_google_client_secret_here
GOOGLE_REDIRECT_URI=http://localhost:8080/oauth/google/callback

# Microsoft Outlook/Calendar OAuth
# Create app at: https://portal.azure.com/
MICROSOFT_CLIENT_ID=your_microsoft_client_id_here
MICROSOFT_CLIENT_SECRET=your_microsoft_client_secret_here
MICROSOFT_TENANT_ID=your_microsoft_tenant_id_here
MICROSOFT_REDIRECT_URI=http://localhost:8080/oauth/microsoft/callback

# ============================================================================
# CALIBRE & DRM REMOVAL
# ============================================================================

# Calibre installation path
CALIBRE_PATH=C:\Program Files\Calibre2

# Calibre library location
CALIBRE_LIBRARY=C:\Users\armad\OneDrive\Calibre Library

# DRM-free ebook output directory
DRM_OUTPUT_DIR=D:\OsMEN\content\ebooks\drm_free

# Extracted text output directory
DRM_TEXT_DIR=D:\OsMEN\content\ebooks\text

# DeDRM plugin configuration path
DEDRM_CONFIG_PATH=C:\Users\armad\AppData\Roaming\calibre\plugins\dedrm.json

# Adobe Digital Editions path (for ACSM processing)
ADE_PATH=C:\Program Files (x86)\Adobe\Adobe Digital Editions 4.5

# Enable OCR for screen capture fallback
DRM_OCR_ENABLED=true

# ============================================================================
# BACKUP CONFIGURATION
# ============================================================================

# Backup directory for automated backups
BACKUP_DIR=./backups

# ============================================================================
# CONVERTX - UNIVERSAL FILE CONVERTER
# ============================================================================

# Enable/disable ConvertX integration
CONVERTX_ENABLED=true

# ConvertX service URL
CONVERTX_URL=http://localhost:3000

# JWT secret for ConvertX (if using authenticated mode)
# Generate with: python3 -c "import secrets; print(secrets.token_hex(32))"
CONVERTX_JWT_SECRET=osmen-convertx-secret-key-change-me

# Allow unauthenticated access (true for local dev, false for production)
CONVERTX_ALLOW_UNAUTHENTICATED=true

# Auto-delete converted files after N hours (0 to disable)
CONVERTX_AUTO_DELETE_HOURS=24

# ============================================================================
# GETTING STARTED TIPS
# ============================================================================
#
# 1. REQUIRED: Change all passwords marked with "CHANGE THIS"
# 2. REQUIRED: Add at least ONE LLM provider API key
# 3. RECOMMENDED: Use OpenAI for easiest setup (get key from platform.openai.com)
# 4. OPTIONAL: Configure Obsidian vault path if using knowledge management
# 5. RUN: python3 scripts/automation/validate_security.py to check config
# 6. START: docker-compose up -d
# 7. VERIFY: python3 check_operational.py
#
# For Librarian RAG features:
# - Start with: docker-compose --profile librarian up -d
# - Ingest docs: POST http://localhost:8200/ingest
# - Query: POST http://localhost:8200/query
# - See LIBRARIAN_INTEGRATION_PLAN.md for details
#
# For detailed setup: see 1stsetup.md or QUICKSTART.md
# ============================================================================
