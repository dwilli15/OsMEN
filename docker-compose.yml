services:
  # Langflow - Visual flow builder for LLM agents
  langflow:
    image: langflowai/langflow:latest
    container_name: osmen-langflow
    ports:
      - "127.0.0.1:7860:7860"
    environment:
      - LANGFLOW_DATABASE_URL=postgresql://langflow:langflow@postgres:5432/langflow
      - LANGFLOW_CONFIG_DIR=/app/config
    volumes:
      - ./langflow/flows:/app/flows
      - ./langflow/config:/app/config
      - langflow-data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
    restart: on-failure:3
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7860/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - osmen-network

  # n8n - Workflow automation
  n8n:
    image: n8nio/n8n:latest
    container_name: osmen-n8n
    ports:
      - "127.0.0.1:5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_BASIC_AUTH_USER:-admin}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_BASIC_AUTH_PASSWORD:-changeme}
      - N8N_HOST=${N8N_HOST:-localhost}
      - N8N_PORT=${N8N_PORT:-5678}
      - N8N_PROTOCOL=http
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=${DB_POSTGRESDB_DATABASE:-n8n}
      - DB_POSTGRESDB_USER=${DB_POSTGRESDB_USER:-n8n}
      - DB_POSTGRESDB_PASSWORD=${DB_POSTGRESDB_PASSWORD:-n8n}
      - EXECUTIONS_DATA_SAVE_ON_SUCCESS=all
      - GENERIC_TIMEZONE=UTC
    volumes:
      - ./n8n/workflows:/home/node/.n8n
      - n8n-data:/home/node/.n8n
    depends_on:
      postgres:
        condition: service_healthy
    restart: on-failure:3
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - osmen-network

  # LM Studio - Primary local LLM (run externally on host)
  # Access at: http://host.docker.internal:1234
  # Instructions: Install LM Studio on host and enable API server

  # Ollama - Secondary local LLM option (optional)
  ollama:
    image: ollama/ollama:latest
    container_name: osmen-ollama
    ports:
      - "127.0.0.1:11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    restart: on-failure:3
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: "4"
          memory: 8G
        reservations:
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - osmen-network
    profiles:
      - ollama
    # Uncomment the following section if you have an NVIDIA GPU
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '4'
    #       memory: 8G
    #     reservations:
    #       memory: 2G
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

  # MCP Server - Model Context Protocol for tool integration
  mcp-server:
    build:
      context: .
      dockerfile: gateway/Dockerfile.mcp
    container_name: osmen-mcp-server
    ports:
      - "127.0.0.1:8081:8081"
    environment:
      - OBSIDIAN_VAULT_PATH=${OBSIDIAN_VAULT_PATH:-}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ${OBSIDIAN_VAULT_PATH:-./obsidian-vault}:/vault:ro
      - ./tools:/app/tools:ro
    restart: on-failure:3
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - osmen-network
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # Agent Gateway - Central API gateway for production LLM agents
  agent-gateway:
    build: ./gateway
    container_name: osmen-agent-gateway
    ports:
      - "8080:8080"
    environment:
      # OpenAI Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}

      # GitHub Copilot Configuration
      - GITHUB_TOKEN=${GITHUB_TOKEN:-}
      - COPILOT_API_URL=${COPILOT_API_URL:-}

      # Amazon Q Configuration
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
      - AWS_REGION=${AWS_REGION:-us-east-1}

      # Anthropic Claude Configuration
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}

      # LM Studio Configuration (host)
      - LM_STUDIO_URL=${LM_STUDIO_URL:-http://host.docker.internal:1234/v1}

      # Ollama Configuration (optional)
      - OLLAMA_URL=${OLLAMA_URL:-http://ollama:11434}

      # Gateway settings
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./gateway/config:/app/config
    restart: unless-stopped
    networks:
      - osmen-network
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # Qdrant - Vector database for memory storage
  qdrant:
    image: qdrant/qdrant:latest
    container_name: osmen-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant-data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped
    networks:
      - osmen-network

  # PostgreSQL - Shared database for Langflow and n8n
  postgres:
    image: postgres:15-alpine
    container_name: osmen-postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=${POSTGRES_DB:-postgres}
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./postgres/init:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - osmen-network

  # Redis - Caching and session management
  redis:
    image: redis:7-alpine
    container_name: osmen-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    restart: unless-stopped
    networks:
      - osmen-network

  # Web Dashboard - Agent Hub Interface
  web:
    build:
      context: .
      dockerfile: Dockerfile.web
    container_name: osmen-web
    ports:
      - "8000:8000"
    environment:
      - WEB_PORT=8000
      - WEB_HOST=0.0.0.0
      - LANGFLOW_URL=http://langflow:7860
      - N8N_URL=http://n8n:5678
      - QDRANT_URL=http://qdrant:6333
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    volumes:
      - ./web:/app/web
      - ./agents:/app/agents
      - ./langflow/flows:/app/langflow/flows
      - ./n8n/workflows:/app/n8n/workflows
      - ./config:/app/config
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    networks:
      - osmen-network

volumes:
  langflow-data:
  n8n-data:
  ollama-data:
  qdrant-data:
  postgres-data:
  redis-data:

networks:
  osmen-network:
    driver: bridge
