Chapter 10 What Governments and Tech Companies Can Do Now How do we consume as much of your time and conscious attention as possible?” That’s Sean Parker, the first president of Facebook, in a 2017 interview. [1] He was describing the thought process of the people who created Facebook and the other major social media platforms in the 2000s. In chapter 2, I quoted another line from this interview, in which Parker explained the “social-validation feedback loop” by which these companies exploit “a vulnerability in human psychology.” The apps need to “give you a little dopamine hit every once in a while, because someone liked or commented on a photo or a post or whatever. And that’s going to get you to contribute more content, and that’s going to get you... more likes and comments.” He said that he, Mark Zuckerberg, Kevin Systrom (cofounder of Instagram), and others “understood this consciously. And we did it anyway.” He also said, “God only knows what it’s doing to our children’s brains.” Why would anyone treat their customers that way? Because the users are not really the customers for most social media companies. When platforms offer access to information or services for free, it’s usually because the users are the product. Their attention is a precious substance that companies extract and sell to their paying customers—the advertisers. The companies are competing against each other for users’ attention, and, like gambling casinos, they’ll do anything to hold on to their users even if they harm them in the process. We need to change the incentives so that companies behave differently, as has happened in many other industries. Think of food safety regulations in the Progressive Era, or automotive safety regulations in the 1960s, both of which contributed to the long-running decline in children’s mortality rates. [2] In the first part of this chapter, I describe the ways that many tech companies, particularly social media companies, employ design features that answer Sean Parker’s question about how to consume more of people’s attention, distracting them from spending needed time in the real world. I then lay out how governments can change laws to incentivize different behavior and design choices, which would make social media less harmful and make it easier for parents to make their own choices about how and when their children enter the virtual world. In the second part of the chapter, I show how governments can change laws and policies that push parents and schools to overprotect in the real world. I also show how governments can make the real world more inviting for children, more supportive of their needs for play, autonomy, and responsibility. As we’ll see, government policies have contributed to the decline of the play-based childhood (especially through the overzealous enforcement of vague state laws about child neglect) and to the rise of the phone-based childhood (especially by setting the age of internet adulthood too low and not enforcing it). New legislation and new enforcement policies would be a tremendous help for parents who are struggling to raise their children in a healthier way. [*] The Race to the Bottom of the Brain Stem Among the keenest analysts of the incentives driving tech companies is Tristan Harris, a former ethicist at Google who, in 2013, created a PowerPoint presentation for his fellow Google employees titled “A Call to Minimize Distraction and Respect Users’ Attention.” [3] Harris noted that the products made by just three companies—Google, Apple, and Facebook—were shaping how most of humanity spent its limited attention, and they were draining it away carelessly or deliberately. The design choices made by tech companies, Harris asserted, had resulted in a global collapse of the amount of attention available for anything beyond screens. Harris left Google in 2015 and later founded the Center for Humane Technology, an important organization that has been raising the alarm and offering solutions ever since. In 2020, he was invited to testify to a U.S. Senate committee hearing on consumer protection. In his testimony, Harris laid out the incentives companies face in their ferocious competition to extract attention. There are are a number of psychological vulnerabilities that can be abused to capture attention, some of which are grounded in our most basic needs. The companies are stuck in a collective action problem known as a race to the bottom, he said, because if one of them fails to exploit an available psychological weakness, it puts itself at a disadvantage relative to less scrupulous competitors: [4] In an attention economy, there’s only so much attention and the advertising business model always wants more. So, it becomes a race to the bottom of the brainstem.... It starts small. First to get your attention, I add slot machine “pull to refresh” rewards which create little addictions. I remove stopping cues for “infinite scroll” so your mind forgets when to do something else. But then that’s not enough. As attention gets more competitive, we have to crawl deeper down the brainstem to your identity and get you addicted to getting attention from other people. By adding the number of followers and likes, technology hacks our social validation and now people are obsessed with the constant feedback they get from others. This helped fuel a mental health crisis for teenagers. [5] The advertising-driven business model turns users into the product, to be hooked and reeled in. Personalization makes social media companies far more powerful than companies were in pre-digital ad-driven industries such as newspapers and broadcast TV. If we focus on that fact, we can then begin to see where legislation can play a helpful, targeted role, not just regarding social media, but also for video games and pornography sites, which use many of the same attention-grabbing and data-extracting techniques on minors. For businesses that earn revenue based on displaying ads alongside user-generated content, there are three basic imperatives: (1) get more users, (2) get users to spend more time using the app, and (3) get users to post and engage with more content, which attracts other users to the platform. One way that companies get more users is by failing to enforce their own rules prohibiting users under 13. In August 2019, I had a video call with Mark Zuckerberg, who, to his credit, was reaching out to a wide variety of people, including critics. I told him that when my children started middle school, they each said that most of the kids in their class (who were 10 or 11 at the start of sixth grade) had Instagram accounts. I asked Zuckerberg what he planned to do about that. He said, “But we don’t allow anyone under 13 to open an account.” I told him that before our call I had created a fake account for a fictional 13-year-old girl and I encountered no attempt to verify my age claim. He said, “We’re working on that.” While writing this chapter (in August 2023), I effortlessly created another fake account. There is still no age verification, even though age verification techniques have gotten much better in the last four years, [6] nor is there any disincentive for preteens to lie about their age. If Instagram were to make a real effort to block or expel underage users, it would lose those users to TikTok and other platforms. Younger users are particularly valuable because the habits they form early often stick with them for life, so companies need younger users to ensure robust future usage of their products. They therefore view the loss of market share among younger users as an existential threat. [7] As a result, companies that make products used by adolescents are trapped in another race to the bottom, a race to get younger and younger users. Documents brought out by the whistleblower Frances Haugen show that Meta has long been trying to study and attract preteens, and has even considered how to reach children as young as 4. [8] (The same race to the bottom occurred with tobacco companies targeting their ads to adolescents, and denying it.) As for the second imperative, one way that companies get users to spend more time on their apps is by using artificial intelligence to select what to put into a user’s feed. Based on the time users spend viewing different kinds of content, AI then serves them more such content. [9] This is why short-form video platforms like TikTok and Instagram Reels are said to be so addictive: Their algorithms are able to quickly detect whatever it is that makes users pause as they scroll, which means they can pick up on unconscious wishes and interests that the user may not even be aware of, leading a minor to be served inappropriate sexual content, for example. [10] Technology designers long ago learned that reducing friction or effort increases time spent, so features like autoplay and infinite scroll encourage increased consumption of content in an automatic, zombie-like way. When people are asked to identify the platforms on which they spend more time than they want to, the “winners” are social media platforms with these features. [11] Modern video games use different tricks to keep users playing such as free-to-play business models, validation feedback loops, “loot boxes” that are essentially gambling, and never-ending multiplayer games. To achieve their third objective—incentivizing users to post more content—platforms take advantage of the fact that adolescents are highly sensitive to social status and social rewards. Features like Snapchat “streaks” gamify social interaction by encouraging users to send a picture to their friends every day, in order to not break a publicly visible streak. Snapchat streaks pressure kids to spend more time than they themselves want to spend maintaining network connections, leaving less time for real-world interaction. Another example is setting people’s privacy settings to public by default, so that whatever they post becomes content for the largest possible pool of users. Minors should be protected from products that are designed to addict them. I wish that companies would treat children and adolescents with more care on their own, but given market incentives and business norms, it is likely to take legislation to force them to do so. What Governments and Tech Companies Can Do to End the Race to the Bottom of the Brainstem There are four main ways that governments and tech companies could improve the virtual world for adolescents. 1. Assert a Duty of Care In 2013, the British filmmaker Beeban Kidron made a documentary called InRealLife, about the lives of teens in the online world. What she learned about the ways tech companies exploit adolescents alarmed her. While she was working on the film, she was awarded a life peerage in the U.K. Parliament’s House of Lords, which gave her a new way to act on her concerns. She made online child safety her top priority. After much consultation, she developed a list of design standards that tech companies could adopt that would make time online less harmful to children and adolescents. The list came to be called the Age Appropriate Design Code (AADC), and it was enacted in the U.K. in June 2020. The code was revolutionary for asserting that companies have some moral and legal responsibility for how they treat minors. They have a duty to design their services in the “best interests” of children, and the code defines children as anyone under the age of 18. For example, it is usually the case that the best interest of the child is served by setting all defaults about privacy to the highest standard, while the best interest of the company is served by making the child’s post visible to the widest audience possible. The law therefore requires that the default settings for minors be private; the child must make an active choice to change a setting if she wants her posts to be viewable by strangers. Same thing for geolocation data; the default should be that nobody can find the location of a child from a post or from the use of an app, unless the child elects to make such data public. Another stipulation: Platforms must be transparent and clear about what they are doing, explaining their privacy policies and the nature of parental controls in language (or perhaps videos) easy for children to understand. While the code applied only to services offered in the U.K., the law has already had two broader effects. First, many of the tech companies decided that it wasn’t worth the difficulty to offer different products in different countries, so they made a few of the changes globally. Second, the State of California adopted its own version of the AADC, which was passed into law in 2022, and other states have since passed their own versions. [12] Of course, it makes little sense for individual U.S. states to enact their own laws about something as sprawling and placeless as the internet. It would be far preferable for the U.S. Congress to act, and there is now strong bipartisan support for several important bills, such as the Kids Online Safety Act (KOSA), which includes many ideas from the AADC. [13] But given the longstanding paralysis of U.S. Congress, it has fallen to individual states and governors to try to protect the children in their states from predatory online practices. Some critics worry that if there is government regulation, it means that the government will be telling people what they can and cannot say on the internet, and the government might well censor one side of the political spectrum or the other. This fear is not unreasonable. [14] But most of the harms platforms are responsible for are not about what other users are posting (which is hard for platforms to monitor and control [15] ) but about design decisions that are 100% within the control of the platforms and that incentivize or amplify harmful experiences. [16] Recent laws such as KOSA are written to focus on design, not content. Design changes—such as setting privacy preferences to maximum by default—don’t give an advantage to either side of the political spectrum. When TikTok limited the ability of teenagers to be contacted by strangers via direct message [17] in response to the U.K. code, or when Facebook pulled back on how advertisers could target underage users with personalized ads, [18] these changes were “viewpoint neutral.” [19] 2. Raise the Age of Internet Adulthood to 16 In the late 1990s, as the internet was becoming a part of life, there were no special protections for children online. Companies could collect and sell children’s data without the knowledge or consent of their parents. In response, the U.S. Federal Trade Commission recommended that Congress enact legislation requiring websites to obtain parental consent before collecting personal information from children. Representative (now senator) Ed Markey, from Massachusetts, drafted such a bill, and he defined a child as anyone under the age of 16, for data collection purposes. The e-commerce companies of that era objected, and they teamed up with civil liberties groups who were concerned that the new bill would make it harder for teens to find information about birth control, abortion, or other sensitive topics. [20] In the negotiations over the bill, a compromise was reached that the age would be lowered to 13. That decision had nothing to do with adolescent brain development or maturity; it was just a political compromise. Nonetheless, 13 became the de facto age of “internet adulthood” for the United States, which effectively made it the age of internet adulthood for the world. Anyone who is 13, or at least says they are, can be treated as an adult for the purposes of data acquisition. As Senator Markey later said, “It was too young and I knew it was too young then. It was the best I could do.” [21] In addition to setting the age too low, the bill, known as COPPA (Children’s Online Privacy Protection Act), failed to impose any obligation on companies to verify anyone’s age. They were only required to avoid collecting data from users when they had direct evidence that the user was under 13. The bill was enacted in 1998, when the internet was a very different place than it is today, and there has been no subsequent action by Congress since then (although several bills are being considered in 2023, including an update of COPPA that would raise the age back to 16). By specifying 13 as the age of adulthood, COPPA sent a signal to parents that the government thinks 13 is an appropriate age for children to be opening accounts and using these services. It sounds like the “PG-13” by which the Motion Picture Association tells parents that a movie is appropriate for a 13-year-old to see without a parent. But readiness to see a movie is very different from readiness to exercise self-control and make wise choices while being subjected to the addictive attention-extracting techniques used by powerful companies. What is the right age of internet adulthood? Note that we are not talking about the age at which children can browse the web or watch videos on YouTube or TikTok. We’re talking only about the age at which a minor can enter into a contract with a company to use the company’s products. We’re talking about the age at which a child can open an account on YouTube or TikTok and begin uploading her own videos and getting her own highly customized feed, while giving her data to the company to use and sell as it says it will do in its terms of service. Even parents who try hard to keep their children off Instagram often fail, like the mother in Boston whom I quoted in chapter 1, or like Alexis Spence’s parents, from chapter 6. When I spoke with the Spences, Alexis’s mother described her challenge like this: “I’m fighting AI and I can’t beat that. I can’t beat a computer that is smarter than me and that is telling her how to outwit me.” We can’t put the entire burden of policing minimum ages on parents, any more than we would do so when teens try to buy liquor. We expect liquor stores to enforce age limits. We should expect the same from tech companies. I don’t think we should raise the age of internet adulthood all the way to 18. I think Markey’s original choice of 16 was the right one for the minimum age at which minors can accept terms of service and give away their data. At 16, adolescents are not adults, but they are more mature and capable than they were at 13. They are also just beyond what may be the most sensitive period for harm from social media (11–13 for girls, 14–15 for boys [22] ). On the other hand, their frontal cortices are still developing, and they are still vulnerable. Social media, video games, porn, and other addictive activities will still harm many of them in a variety of ways. So I’m not saying that the virtual world in its present form, with no guardrails, is safe for 16-year-olds. I’m just saying that if we’re going to write a minimum age into law and make it an enforceable national standard, then 13 is way too low and 16 is a more reasonable and achievable compromise. It would gain more political and social support than an effort to raise the age to 18. I would just add that 16- and 17-year-olds are still minors, and the protections in any version of an Age Appropriate Design Code should still apply to them. I therefore believe that the U.S. Congress should fix the mistakes it made in 1998 and raise the age of internet adulthood from 13 back to 16, as it was in the original draft of the bill, and then require companies to enforce it. Now, how can companies do that? 3. Facilitate Age Verification When people hear the term “age verification,” they seem generally to assume it means that users must show a government ID card, such as a driver’s license, in order to open an account or access a website. That is one way to do it, and it is the way that Louisiana mandated in a 2023 law. The law required sites whose content is more than one-third pornographic to verify that visitors were over 18, using the state’s digital wallet app to present their Louisiana driver’s license. Of course, few visitors to a porn site would be willing to give the site their real name, let alone an image of their driver’s license. In response, Pornhub simply blocked access to its site from residents who appear to be in Louisiana. Could social media platforms require an ID of all users to prove that they are old enough to open an account? In theory, yes. States could easily provide identification cards for young people who do not yet have a driver’s license. But in practice, platforms get hacked with some regularity, and their databases get sold to thieves or posted on the web, so the threat to privacy would be substantial. Many people would refrain from using valuable services because of it. I am opposed to legally mandating the use of government-issued identity cards for access to parts of the internet run by non-government entities. Are there ways of verifying age that would still allow people to use a site anonymously? Yes. A second approach to age verification is to have sites farm the job out to another company that simply reports back to the platform: yes or no. Old enough, or not old enough. [23] If the age verification company was hacked, all that the world would learn is that the people in their database once had their age verified, not that they had used Pornhub or any other site. Companies have developed methods such as these: Using a network of people to vouch for each other (such that those who lie lose the privilege of vouching). Issuing a blockchain token to anyone who is verified once, by a reliable method. The token then serves like a driver’s license to prove that the bearer is above a certain age, but it carries no personal information about the bearer, so a data hack would reveal nothing. Using biometrics to establish identity. Clear, a company known for rapid identity verification in airports, is now used as a quick way for its clients—who previously verified their age—to prove that they are old enough to buy alcohol at stadium events. So many companies now offer different methods of age verification that they have their own trade association. [24] The quality, reliability, and security of these methods are sure to increase over time. I hope that companies that want to enforce a minimum age will begin to offer a menu of options from which the user can pick. [25] Some of the methods would take only a few seconds. Laws such as the one in Louisiana would create far smaller privacy concerns if they allowed companies to offer a menu of reliable options, rather than mandating the use of a government-issued ID. There is not, at present, any perfect method of implementing a universal age check. There is no method that could be applied to everyone who comes to a site in a way that is perfectly reliable and raises no privacy or civil liberties objections. [26] But if we drop the need for a universal solution and restrict our focus to helping parents who want the internet to have age gates that apply to their children, then a third approach becomes possible: Parents should have a way of marking their child’s phones, tablets, and laptops as devices belonging to a minor. That mark, which could be written either into the hardware or the software, would act like a sign that tells companies with age restrictions, “This person is underage; do not admit without parental consent.” A simple way to do this would be for Apple, Google, and Microsoft—who create the operating systems that run nearly all of our devices—to add a feature to their existing parental controls. In Apple’s iOS, for example, parents already set up family accounts and put in the correct birth dates for their children when they give them their first iPhones. The parent already gets to choose whether to allow the child to download only age-appropriate apps, movies, and books from Apple’s own services. Why not just expand that ability so that a parent’s choice is respected by all platforms for which age restrictions are appropriate, or required by law? (Parents already have the ability to block access to specific websites, but that puts the onus on parents to know what sites and categories of sites they want to block, which parents can’t know unless they monitor their children’s online activity closely and monitor online sites and trends. [27] ) Apple, Google, and Microsoft could create a feature, let’s call it age check, which would be set to “on” by default whenever a parent creates an account for a child under the age of 18. The parent can choose to turn age check off, but if on is the default, then it would be very widely used (unlike many features in current parental controls, which many parents don’t know how to turn on). If age check is left on, then when anyone uses that phone or computer to try to open an account or log in to an account, the site can simply verify by communicating with the device to answer two questions: 1) Is age check on? If so, then 2) Does the person meet our minimum age? (For example, 16 to open or access a social media account, 18 to access pornography.) This kind of device-based verification offers a way that parents, tech companies, and platforms can share responsibility for age verification. Such a system would have helped Alexis Spence’s parents to keep their 10-year-old daughter off the social media platforms that took over her life. It would also have reduced the peer pressure on Alexis because few of her classmates would have been on Instagram. It would also allow sites to age gate specific features, such as the ability to upload videos or to be contacted by strangers. Note that with device-based verification, nobody else is inconvenienced. Adults who visit a site that uses age check don’t have to do anything or show anything, so the internet is unchanged for them, and there is no privacy threat whatsoever. Parents who want their children to open social media accounts or visit pornography websites can simply turn age check off. 4. Encourage Phone-Free Schools In the next chapter—on what schools can do—I’ll make the case that all schools, from elementary through high school, should go phone-free to improve not only mental health but academic outcomes as well. Governments at all levels, from local to federal, could support this transition by allocating funds to pay the small cost of buying phone lockers or lockable pouches for any school that wants to keep phones out of students’ pockets and hands during the school day. Departments of education at the state and federal levels could support research on the effects of phone-free schools, to verify whether they are beneficial for student mental health and academic performance. What Governments Can Do to Incentivize More (and Better) Real-World Experience During the summer of 2014, when the South Carolina single mom Debra Harrell worked her shifts at McDonald’s, she brought along her daughter, who was on vacation from school. Regina, age 9, spent the time playing on a laptop. But when the laptop was stolen from their home, Regina begged her mom to let her play at the neighborhood’s popular sprinkler park instead. She’d be surrounded by friends and many of their parents. It felt safe. It felt like summer. Debra said yes. But on Regina’s third day of fun in the sun, a woman at the park asked her where her mom was. When she said, “Working,” the woman called 911. The police charged Debra with child abandonment—which carries up to a 10-year sentence—and threw her in jail. Regina was taken away from her mom for 17 days. [28] This case and many others like it frighten parents into over-supervising their children. Governments are literally criminalizing the play-based childhoods that were the norm before the 1990s. 1. Stop Punishing Parents for Giving Children Real-World Freedom Debra’s experience and other stories of parents investigated for things like letting children play outside [29] or get themselves home from the park [30] led Let Grow to start a movement for “Reasonable Childhood Independence” laws. Currently, neglect laws in most states are vague, saying things like “Parent must provide proper supervision.” Yes, of course they should, but people have wildly different ideas of what that entails. Just because some passerby wouldn’t let her nine-year-old play outside doesn’t mean the state should be able to investigate anyone who does. A study in Social Policy Report found that the way current U.S. laws are written and interpreted has little relationship to the ages at which children develop abilities. [31] In societies around the world, children were traditionally thought to become much more capable and responsible around the ages of 6 or 7, when they were routinely given responsibilities such as caring for younger children and animals. Yet in some U.S. states, such as Connecticut, the law said a child should never be left alone in public before the age of 12, meaning that 11-year-olds needed babysitters. Indeed, a Connecticut mom was arrested for letting her 11-year-old wait in the car while she ran into the store. [32] This, despite the fact that the Red Cross begins training babysitters at the age of 11, which is the age at which my sisters and I began to babysit for neighbors. Let Grow lobbied successfully for Connecticut to change its criminal endangerment law in 2023. But other states’ neglect laws remain ambiguous, allowing the authorities wide discretion to intervene. The Social Policy Report essay notes, “Parents who fail to provide their children opportunities for physical and cognitive stimulation through independent activities are potentially ‘neglecting’ their children in those dimensions.” So a lack of adult supervision should not be the touchstone for a neglect finding. In fact, maybe the state is engaging in neglect when it mandates overprotection. Reasonable Childhood Independence laws clarify the meaning of neglect: Neglect is when a parent blatantly, willfully, or recklessly disregards a danger to a child so apparent that no reasonable person would allow the child to engage in that activity. In other words, it is not neglect when you simply take your eyes off your children. This clarification protects parents who give their kids more independence for its own sake, as well as those who do so out of economic necessity, like Debra Harrell. In 2018, Utah became the first U.S. state to pass such a law. Since then, Texas, Oklahoma, Colorado, Illinois, Virginia, Connecticut, and Montana have too. These bills have usually had bipartisan sponsors, and they often passed unanimously. They appeal to people across the political spectrum because no one wants the government meddling in family life if there is not a compelling reason. The government’s job is to protect children from actual abuse, not from the everyday activities of childhood. States must revise their supervisory neglect laws. They must cease and desist all enforcement action against parents whose only offense is that they chose to give their children reasonable independence, appropriate for their age. Ask your state legislators (or equivalent in other countries) to introduce a Reasonable Childhood Independence law. [33] 2. Encourage More Play in Schools In the next chapter, I’ll make the case that schools in the United States are starving children of playtime in order to make ever more room for academic training and test preparation, which backfires because play-deprived kids become anxious and unfocused. Ultimately, they learn less. Governors’ offices and state education departments should take seriously the research on the benefits of free play in general and recess in particular. [34] Then they should mandate that schools give a lot more of it, including play opportunities before and after school, especially in elementary and middle school. [35] 3. Design and Zone Public Space with Children in Mind If we want children to meet each other face-to-face and interact with the real world—not just screens—the world and its inhabitants have to be accessible to them. A world designed for automobiles is often not one that children find accessible. Cities and towns can do more to be sure that they have good sidewalks, crosswalks, and traffic lights. They can install traffic calming measures, and they can change their zoning to allow more mixed-use development. When commercial, recreational, and residential establishments are more mashed up together, there is more activity on the street and more places that children can get to on foot or by bike. But when the only way for a kid to get to a shop, park, or friend’s house is by “parent taxi,” more kids will end up at home on a screen. One study found that kids who can get to a playground by bike or foot are six times more likely to visit it than kids who need someone to drive them. [36] So scatter playgrounds throughout a neighborhood, and consider having a few of them be adventure playgrounds (see next chapter). One innovative and inexpensive way that European cities are helping kids (and parents) to be more sociable is by blocking off the street in front of a school for an hour before and after school. [37] On these temporarily car-free School Streets, parents mingle and kids play, even as congestion, pollution, and road danger go down. Cities can make this happen by easing the street closure permitting process. In our era of declining community and rising loneliness, cities and towns should make it easy for local residents to block off streets for block parties and other social reasons too, including Play Streets (streets closed to traffic, part time, so kids can play with each other, like old times). [38] When considering transit, zoning laws, permits, and new construction, remember that kids are human beings. They want to be where the action is. Easily accessible mixed-use spaces where everyone, young and old, can hang out, see, be seen, do some playing, shopping, eating, flirting, and, when tired, bench sitting make everyone more engaged with the world beyond the screen. 4. More Vocational Education, Apprenticeships, and Youth Development Programs The educational system in the United States has become ever more focused on academic training that leads to a college education. There has been a corresponding decline in course offerings and student participation in what is known as career and technical education, or CTE. These are courses with a lot of hands-on experience in areas such as shop, auto mechanics, agriculture, and business. Richard Reeves says the research is strongest on the benefits of sending boys to specialized high schools devoted to CTE. Boys in such schools saw big gains in their graduation rates and later earnings, compared with similar boys who attended traditional high schools, while girls did not show these particular benefits. [39] These findings are further evidence that standard schools are failing to engage many boys, leading to enormous wasted potential. Apprenticeships have also been shown to be effective for helping young people make the transition from high school to paid employment. In a labor market in which people move around frequently, companies have little incentive to take on untrained young people, invest in them, and then have them move elsewhere. Government-supported programs that subsidize pay for a period of time make it less expensive for companies to train young people, thereby increasing their value to the company or any future employer. [40] Governments can also support gap year and “year of service” programs, particularly among young people who do not have clear college prospects. Programs like AmeriCorps help young people learn new skills while helping local communities. Wilderness experience programs have also been shown to confer benefits to adolescents; [41] they offer direct training in antifragility while immersing young people in natural beauty. Such programs are usually run by nonprofit or for-profit companies, but the State of Connecticut has been running a tuition-free program since 1974 for adolescents across the state. [42] Governments have the power and often the responsibility to address collective action problems. Poorly crafted and erratically enforced laws have exacerbated some of these problems. Governments can set standards that change the behavior of companies. They can set age limits that shut off competition for underage users. They can make it easier for parents and schools to grant more freedom to children and adolescents, as I’ll discuss in the next two chapters. When governments, tech companies, schools, and parents work in complementary ways, they can collectively solve hard problems, including improving the mental health of young people. In Sum Governments at all levels need to change policies that are harming adolescent mental health and support policies that would improve it. In the United States, governments at the state and local level are partly responsible for the overprotection of children in the real world (via vast overreach of vague neglect laws), and the federal government is partly responsible for the underprotection of children in the virtual world (by passing an ineffective law in 1998 and failing to update it as the dangers of life online became more apparent). To correct underprotection online, national and federal governments should enact laws of the sort first passed in the U.K., which require companies to treat minors differently than adults, with an extra duty of care. National governments should also raise the age of internet adulthood to 16. Tech companies can be a major part of the solution by developing better age verification features, and by adding features that allow parents to designate their children’s phones and computers as ones that should not be served by sites with minimum ages until they are old enough. Such a feature would help to dissolve multiple collective action problems for parents, kids, and platforms. To correct overprotection in the real world, state and local governments should narrow neglect laws and give parents confidence that they can give their children some unsupervised time without risking arrest or state intervention in their family life. State and local governments should also encourage more free play and recess in schools. They should consider the needs of children in zoning and permitting, and they should invest in more vocational education and other programs that have been shown to help adolescents, especially boys, make the transition to adulthood. OceanofPDF.com